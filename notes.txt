# Notes from AI engineering workshop

- agents are programs where LLM outputs control workflow
- it involves the following
    - multiple llm calls
    - llms can use tools
    - environment where llms can interact
    - planner to coordinate activity
    - autonomy
- LLMs today can't do too well on the HLE (humanity's last exam) benchmark. Agents with chain of thought and other back and forth reasoning abilities can do considerably well on these
- agents are good at repatitive tasks, automate/augment tasks
- there are significant tailwinds in this world today to create agentic systems
- Basic tasks:
    - code generation - team of Software developers
    - medical diagnosis
    - scientific literature review
    - design and run experiments/do literature review
    - replace enterprise tasks like customer support
- types of agentic systems:
    - workflow: predefined paths where LLMs are orchestrated
    - agents: LLMs dynamically decide how to proceed
- llm doesnt necessarily look into the file system. actually, the code interacts with the llm to get the 'commands' to learn what to do. then the code does the tasks.
- risks
    - unpredicable path, output and costs
    - this can be controlled by proper monitoring
    - guardrails that ensure that agents work ethically
- few frameworks
    - no framework (conect via APIs) (BASIC)
    - MCP (connect agents with data sources) (BASIC)
        * removes the need for glue code
        * think of USB C that connects different components
    - OpenAI Agents SDK (MED)
    - CrewAI - used for multi agent systems. used with yaml files (configs) (idk what this means but let's wait) (MED)
    - Langgraph (ADVANCED)
    - AutoGen (ADVANCED)

# OpenAI Agents SDK
- Its lightweight, easy to use
- terminologies:
    - agents - represent LLMs
    - handoffs - represdent interaction
    - guradrails - controls
- 3 steps to create agents in OpenAI SDK
    - create instance of agent called Agent
    - context manager called trace() to describe what to do
    - Runner.run() kick off the workflow

# Coding exercise 1 - creating deep research

- Pydantic - write schema to define how the output should look like.

- workflow design patterns (building effective agents)
    - prompt chaining - decompose into fixed substask (in -> llm1 -> [gate] -> llm2 -> llm3 -> out)
        * there is more control, you can check traces
        * there can be guardrails for each step, easier to debug
        * for example content creation pipeline (create outline -> [check for brand guidelines] -> write a draft -> polish + SEO -> output)
    - routing - direct an input to a specialized sub task (in -> router routes to [LLM1] [LL2] -> out)
        * eg - medical situations (query of medical info, router routes to different 'specialist' agent)
    - parallelization - break down tasks and run substacks concurrently
        * similar to routing, but you have a coordinator (code) and an aggregator (code)
        * differnet agents can be doing the same sub tasks, and the aggregator can do some operation on that or choose the best (whatever best means)
    - Orchestrator-worker - complex tasks are broken down and done systematically
        * different llms in specific tasks, similar to parallelization
    - evaluator - optimizer - LLM output is validated by another
        * diagram: input -> generator and evaluator do back and forth -> accepted -> output
        * code generation and review is an example. education content generation, the evaluator looks at whether the output is complient with kids, relevant etc

- by contrast, agents:
    - open-ended
    - there is a feedback loop
    - costs could be higher
    - there is no fixed path

    In general, they are flexible within an environment, and the environment can be very loosely defined. it then takes some action or it reaches the end state

# CrewAI
- Agent - autonomous unit (say LLM) with a role, goal, backstory, memory, tools
- Tasks - a specific assignment to be carried out; has description, expected output, agent
- Crew - a team of agents and tasks that run sequentially or hierarchical 

- 5 steps of crewAI project
    - create a project: 'crewai create crew my_project'
    - fill yaml files for config to define agents and tasks
    - complete crew.py module to create Agents, Tasks and Crew, referencing the config`
    - update main.py to set inputs

- Give agents coding skills
- building an engineering team (engineering lead, backend engineer, frontend engineer, test engineer)
- syntax is very important, it can get clunky otherwise

# MCP

- Model context Protocol - USB C for agentic applications
- It is not:
    - a framework fpr building agents
    - fundamental change to how agents work
    - way to code agents
- It is:
    - a protocol - a standard
    - simple way to integrate tools, resources, prompts
- Reasons not to be excited
    - lanchain has big tool ecosystem
    - its just a standard
    - you can alread make functions into tools
- Reasons to be excited
    - makes it frictionless to integrate
    -it is taking off

- Core concepts:
    - 3 key components:
        * host - LLM app like claude or an agentic architecture
        * client: lives inside the host and connects 1:1 to MCP server (each client is connected with one server)
        * server: provides tools, context, prompts etc
    Example: Google maps (MCP server) with goelocation tools. We can configure the host (claude desktop) to run the mcp client and then launches the google maps MCP server on the computer

- misconception: mcp runs remotely: not particularly. most commone scenario is that you download the server on a local system and then run it
- why make an MCP server?
    - allows you to share it with other and help them incorporate tools and resources
    - consistently incorporate all MCPs - if an applications call on a bunch of MCPs, there could be an inconsistency
    
